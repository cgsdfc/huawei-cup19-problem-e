{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "74d806f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pathlib import Path as P\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['KaiTi', 'SimHei', 'FangSong']  # 汉字字体,优先使用楷体，如果找不到楷体，则使用黑体\n",
    "plt.rcParams['font.size'] = 12  # 字体大小\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 正常显示负号\n",
    "from collections import defaultdict\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a4207b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "train_size=0.8\n",
    "seqlen=6\n",
    "bs=32\n",
    "epochs=200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4f3674",
   "metadata": {},
   "source": [
    "这些是模型的超参数。\n",
    "- learning_rate 是学习率，控制模型收敛的快慢，太大了模型容易发散，太小了模型收敛很慢；\n",
    "- train_size 训练集占整个数据集的比例，一般是28开；\n",
    "- seqlen：序列长度，在时序建模中，就是用前几个样本来预测当前样本；\n",
    "- bs：batch size，批量大小，随机梯度下降算法SGD中，每次用来估计梯度的训练样本数量；\n",
    "考虑到数据集本身只有100多个样本，批量不用太大；\n",
    "- epochs：训练的轮数，即迭代次数；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e2d95214",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('问题2-训练数据-归一化.csv',index_col='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "550eb32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, train_size=train_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b743583",
   "metadata": {},
   "source": [
    "将数据集分割为训练集和验证集，二者没有交集，训练集用来训练模型，验证集用来确保模型没有过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "223f78fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((98, 7), (25, 7))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_size=df_train.shape[1]\n",
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f766de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    df_train.values, df_train.values, sequence_length=seqlen, batch_size=bs, shuffle=True)\n",
    "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    df_val.values, df_val.values, sequence_length=seqlen, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe07d53",
   "metadata": {},
   "source": [
    "利用keras的接口构造时序模型需要的时序数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "33d6dca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 7), dtype=tf.float64, name=None))>,\n",
       " <BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 7), dtype=tf.float64, name=None))>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train, dataset_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4d69d",
   "metadata": {},
   "source": [
    "构建一个单层的LSTM模型。LSTM是一种专门用来建模时序数据的神经网络模型，即长短期记忆（Long Short Term Memory）。\n",
    "可以展开说说理论。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a1bed2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 6, 7)]            0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 5)                 260       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 7)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 302\n",
      "Trainable params: 302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=(seqlen, feature_size))\n",
    "lstm_out = keras.layers.LSTM(5)(inputs)\n",
    "outputs = keras.layers.Dense(feature_size)(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc23e81",
   "metadata": {},
   "source": [
    "训练模型：\n",
    "1. 使用的损失函数：MSE，Mean Square Error，即均方误差；\n",
    "2. 早停止：当验证误差经过一段时间不再改进之后，停止训练模型，这是一种停止训练循环的策略；\n",
    "3. 检查点：当验证误差出现改进时，保存当前的模型参数；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4d6def6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/3 [=========>....................] - ETA: 3s - loss: 0.4122\n",
      "Epoch 1: val_loss improved from inf to 0.37868, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 2s 218ms/step - loss: 0.3809 - val_loss: 0.3787\n",
      "Epoch 2/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3278\n",
      "Epoch 2: val_loss improved from 0.37868 to 0.36398, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3631 - val_loss: 0.3640\n",
      "Epoch 3/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3801\n",
      "Epoch 3: val_loss improved from 0.36398 to 0.35080, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.3471 - val_loss: 0.3508\n",
      "Epoch 4/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3210\n",
      "Epoch 4: val_loss improved from 0.35080 to 0.33918, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3317 - val_loss: 0.3392\n",
      "Epoch 5/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3175\n",
      "Epoch 5: val_loss improved from 0.33918 to 0.32894, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.3175 - val_loss: 0.3289\n",
      "Epoch 6/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3409\n",
      "Epoch 6: val_loss improved from 0.32894 to 0.31993, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.3044 - val_loss: 0.3199\n",
      "Epoch 7/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3224\n",
      "Epoch 7: val_loss improved from 0.31993 to 0.31208, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.2921 - val_loss: 0.3121\n",
      "Epoch 8/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2691\n",
      "Epoch 8: val_loss improved from 0.31208 to 0.30522, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2807 - val_loss: 0.3052\n",
      "Epoch 9/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2965\n",
      "Epoch 9: val_loss improved from 0.30522 to 0.29923, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.2703 - val_loss: 0.2992\n",
      "Epoch 10/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2776\n",
      "Epoch 10: val_loss improved from 0.29923 to 0.29402, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.2603 - val_loss: 0.2940\n",
      "Epoch 11/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2466\n",
      "Epoch 11: val_loss improved from 0.29402 to 0.28948, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.2512 - val_loss: 0.2895\n",
      "Epoch 12/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2463\n",
      "Epoch 12: val_loss improved from 0.28948 to 0.28550, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2426 - val_loss: 0.2855\n",
      "Epoch 13/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2299\n",
      "Epoch 13: val_loss improved from 0.28550 to 0.28199, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2346 - val_loss: 0.2820\n",
      "Epoch 14/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2336\n",
      "Epoch 14: val_loss improved from 0.28199 to 0.27885, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2271 - val_loss: 0.2789\n",
      "Epoch 15/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2424\n",
      "Epoch 15: val_loss improved from 0.27885 to 0.27603, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2202 - val_loss: 0.2760\n",
      "Epoch 16/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2086\n",
      "Epoch 16: val_loss improved from 0.27603 to 0.27348, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2133 - val_loss: 0.2735\n",
      "Epoch 17/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2078\n",
      "Epoch 17: val_loss improved from 0.27348 to 0.27110, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.2072 - val_loss: 0.2711\n",
      "Epoch 18/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1854\n",
      "Epoch 18: val_loss improved from 0.27110 to 0.26892, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2011 - val_loss: 0.2689\n",
      "Epoch 19/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2295\n",
      "Epoch 19: val_loss improved from 0.26892 to 0.26680, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1956 - val_loss: 0.2668\n",
      "Epoch 20/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2030\n",
      "Epoch 20: val_loss improved from 0.26680 to 0.26481, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1901 - val_loss: 0.2648\n",
      "Epoch 21/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1828\n",
      "Epoch 21: val_loss improved from 0.26481 to 0.26285, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1846 - val_loss: 0.2628\n",
      "Epoch 22/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2041\n",
      "Epoch 22: val_loss improved from 0.26285 to 0.26088, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1799 - val_loss: 0.2609\n",
      "Epoch 23/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1925\n",
      "Epoch 23: val_loss improved from 0.26088 to 0.25894, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1750 - val_loss: 0.2589\n",
      "Epoch 24/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1847\n",
      "Epoch 24: val_loss improved from 0.25894 to 0.25696, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1704 - val_loss: 0.2570\n",
      "Epoch 25/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1632\n",
      "Epoch 25: val_loss improved from 0.25696 to 0.25488, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1659 - val_loss: 0.2549\n",
      "Epoch 26/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1616\n",
      "Epoch 26: val_loss improved from 0.25488 to 0.25268, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1614 - val_loss: 0.2527\n",
      "Epoch 27/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1450\n",
      "Epoch 27: val_loss improved from 0.25268 to 0.25035, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1572 - val_loss: 0.2503\n",
      "Epoch 28/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1318\n",
      "Epoch 28: val_loss improved from 0.25035 to 0.24794, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1530 - val_loss: 0.2479\n",
      "Epoch 29/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1833\n",
      "Epoch 29: val_loss improved from 0.24794 to 0.24530, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.1492 - val_loss: 0.2453\n",
      "Epoch 30/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1261\n",
      "Epoch 30: val_loss improved from 0.24530 to 0.24248, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.1449 - val_loss: 0.2425\n",
      "Epoch 31/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1545\n",
      "Epoch 31: val_loss improved from 0.24248 to 0.23943, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1411 - val_loss: 0.2394\n",
      "Epoch 32/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1612\n",
      "Epoch 32: val_loss improved from 0.23943 to 0.23614, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1372 - val_loss: 0.2361\n",
      "Epoch 33/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1217\n",
      "Epoch 33: val_loss improved from 0.23614 to 0.23270, saving model to problem2_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1332 - val_loss: 0.2327\n",
      "Epoch 34/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1313\n",
      "Epoch 34: val_loss improved from 0.23270 to 0.22921, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1295 - val_loss: 0.2292\n",
      "Epoch 35/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1262\n",
      "Epoch 35: val_loss improved from 0.22921 to 0.22538, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.1257 - val_loss: 0.2254\n",
      "Epoch 36/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1098\n",
      "Epoch 36: val_loss improved from 0.22538 to 0.22138, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1218 - val_loss: 0.2214\n",
      "Epoch 37/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1100\n",
      "Epoch 37: val_loss improved from 0.22138 to 0.21734, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1180 - val_loss: 0.2173\n",
      "Epoch 38/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1086\n",
      "Epoch 38: val_loss improved from 0.21734 to 0.21311, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1143 - val_loss: 0.2131\n",
      "Epoch 39/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1046\n",
      "Epoch 39: val_loss improved from 0.21311 to 0.20876, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1106 - val_loss: 0.2088\n",
      "Epoch 40/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1004\n",
      "Epoch 40: val_loss improved from 0.20876 to 0.20431, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1069 - val_loss: 0.2043\n",
      "Epoch 41/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0928\n",
      "Epoch 41: val_loss improved from 0.20431 to 0.19980, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1031 - val_loss: 0.1998\n",
      "Epoch 42/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0996\n",
      "Epoch 42: val_loss improved from 0.19980 to 0.19530, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0995 - val_loss: 0.1953\n",
      "Epoch 43/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0809\n",
      "Epoch 43: val_loss improved from 0.19530 to 0.19091, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0958 - val_loss: 0.1909\n",
      "Epoch 44/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0933\n",
      "Epoch 44: val_loss improved from 0.19091 to 0.18635, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0923 - val_loss: 0.1864\n",
      "Epoch 45/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0936\n",
      "Epoch 45: val_loss improved from 0.18635 to 0.18176, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0888 - val_loss: 0.1818\n",
      "Epoch 46/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0804\n",
      "Epoch 46: val_loss improved from 0.18176 to 0.17728, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0853 - val_loss: 0.1773\n",
      "Epoch 47/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0894\n",
      "Epoch 47: val_loss improved from 0.17728 to 0.17292, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0819 - val_loss: 0.1729\n",
      "Epoch 48/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0828\n",
      "Epoch 48: val_loss improved from 0.17292 to 0.16884, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0786 - val_loss: 0.1688\n",
      "Epoch 49/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0866\n",
      "Epoch 49: val_loss improved from 0.16884 to 0.16487, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0753 - val_loss: 0.1649\n",
      "Epoch 50/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0733\n",
      "Epoch 50: val_loss improved from 0.16487 to 0.16117, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0721 - val_loss: 0.1612\n",
      "Epoch 51/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0725\n",
      "Epoch 51: val_loss improved from 0.16117 to 0.15757, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0691 - val_loss: 0.1576\n",
      "Epoch 52/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0716\n",
      "Epoch 52: val_loss improved from 0.15757 to 0.15404, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0662 - val_loss: 0.1540\n",
      "Epoch 53/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0652\n",
      "Epoch 53: val_loss improved from 0.15404 to 0.15087, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0633 - val_loss: 0.1509\n",
      "Epoch 54/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0620\n",
      "Epoch 54: val_loss improved from 0.15087 to 0.14785, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0607 - val_loss: 0.1478\n",
      "Epoch 55/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0664\n",
      "Epoch 55: val_loss improved from 0.14785 to 0.14509, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0582 - val_loss: 0.1451\n",
      "Epoch 56/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0485\n",
      "Epoch 56: val_loss improved from 0.14509 to 0.14257, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0557 - val_loss: 0.1426\n",
      "Epoch 57/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0450\n",
      "Epoch 57: val_loss improved from 0.14257 to 0.14026, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0535 - val_loss: 0.1403\n",
      "Epoch 58/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0574\n",
      "Epoch 58: val_loss improved from 0.14026 to 0.13825, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0516 - val_loss: 0.1382\n",
      "Epoch 59/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0514\n",
      "Epoch 59: val_loss improved from 0.13825 to 0.13645, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0496 - val_loss: 0.1365\n",
      "Epoch 60/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0461\n",
      "Epoch 60: val_loss improved from 0.13645 to 0.13491, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0479 - val_loss: 0.1349\n",
      "Epoch 61/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0467\n",
      "Epoch 61: val_loss improved from 0.13491 to 0.13355, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0463 - val_loss: 0.1336\n",
      "Epoch 62/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0481\n",
      "Epoch 62: val_loss improved from 0.13355 to 0.13231, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0449 - val_loss: 0.1323\n",
      "Epoch 63/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0473\n",
      "Epoch 63: val_loss improved from 0.13231 to 0.13124, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0437 - val_loss: 0.1312\n",
      "Epoch 64/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0416\n",
      "Epoch 64: val_loss improved from 0.13124 to 0.13037, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0425 - val_loss: 0.1304\n",
      "Epoch 65/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0423\n",
      "Epoch 65: val_loss improved from 0.13037 to 0.12970, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0416 - val_loss: 0.1297\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0391\n",
      "Epoch 66: val_loss improved from 0.12970 to 0.12907, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0406 - val_loss: 0.1291\n",
      "Epoch 67/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0444\n",
      "Epoch 67: val_loss improved from 0.12907 to 0.12863, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0399 - val_loss: 0.1286\n",
      "Epoch 68/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0397\n",
      "Epoch 68: val_loss improved from 0.12863 to 0.12825, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0392 - val_loss: 0.1283\n",
      "Epoch 69/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0360\n",
      "Epoch 69: val_loss improved from 0.12825 to 0.12796, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0386 - val_loss: 0.1280\n",
      "Epoch 70/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0397\n",
      "Epoch 70: val_loss improved from 0.12796 to 0.12773, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0382 - val_loss: 0.1277\n",
      "Epoch 71/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0322\n",
      "Epoch 71: val_loss improved from 0.12773 to 0.12746, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0376 - val_loss: 0.1275\n",
      "Epoch 72/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0344\n",
      "Epoch 72: val_loss improved from 0.12746 to 0.12718, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0373 - val_loss: 0.1272\n",
      "Epoch 73/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0321\n",
      "Epoch 73: val_loss improved from 0.12718 to 0.12705, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0370 - val_loss: 0.1270\n",
      "Epoch 74/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0310\n",
      "Epoch 74: val_loss improved from 0.12705 to 0.12682, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0366 - val_loss: 0.1268\n",
      "Epoch 75/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0380\n",
      "Epoch 75: val_loss improved from 0.12682 to 0.12664, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0364 - val_loss: 0.1266\n",
      "Epoch 76/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0350\n",
      "Epoch 76: val_loss improved from 0.12664 to 0.12654, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0362 - val_loss: 0.1265\n",
      "Epoch 77/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0388\n",
      "Epoch 77: val_loss improved from 0.12654 to 0.12654, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0359 - val_loss: 0.1265\n",
      "Epoch 78/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0342\n",
      "Epoch 78: val_loss did not improve from 0.12654\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0358 - val_loss: 0.1266\n",
      "Epoch 79/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0348\n",
      "Epoch 79: val_loss did not improve from 0.12654\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0356 - val_loss: 0.1265\n",
      "Epoch 80/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0309\n",
      "Epoch 80: val_loss improved from 0.12654 to 0.12630, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0354 - val_loss: 0.1263\n",
      "Epoch 81/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0347\n",
      "Epoch 81: val_loss improved from 0.12630 to 0.12613, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0353 - val_loss: 0.1261\n",
      "Epoch 82/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0381\n",
      "Epoch 82: val_loss did not improve from 0.12613\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0351 - val_loss: 0.1262\n",
      "Epoch 83/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0282\n",
      "Epoch 83: val_loss improved from 0.12613 to 0.12591, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0349 - val_loss: 0.1259\n",
      "Epoch 84/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0335\n",
      "Epoch 84: val_loss improved from 0.12591 to 0.12590, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0348 - val_loss: 0.1259\n",
      "Epoch 85/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0337\n",
      "Epoch 85: val_loss improved from 0.12590 to 0.12575, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0346 - val_loss: 0.1257\n",
      "Epoch 86/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0356\n",
      "Epoch 86: val_loss improved from 0.12575 to 0.12547, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0345 - val_loss: 0.1255\n",
      "Epoch 87/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0320\n",
      "Epoch 87: val_loss improved from 0.12547 to 0.12522, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0343 - val_loss: 0.1252\n",
      "Epoch 88/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0339\n",
      "Epoch 88: val_loss improved from 0.12522 to 0.12502, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0341 - val_loss: 0.1250\n",
      "Epoch 89/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0381\n",
      "Epoch 89: val_loss improved from 0.12502 to 0.12491, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0340 - val_loss: 0.1249\n",
      "Epoch 90/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0382\n",
      "Epoch 90: val_loss improved from 0.12491 to 0.12474, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0339 - val_loss: 0.1247\n",
      "Epoch 91/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0373\n",
      "Epoch 91: val_loss did not improve from 0.12474\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.1248\n",
      "Epoch 92/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0313\n",
      "Epoch 92: val_loss did not improve from 0.12474\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0336 - val_loss: 0.1249\n",
      "Epoch 93/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0346\n",
      "Epoch 93: val_loss improved from 0.12474 to 0.12464, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0334 - val_loss: 0.1246\n",
      "Epoch 94/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0297\n",
      "Epoch 94: val_loss did not improve from 0.12464\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0333 - val_loss: 0.1247\n",
      "Epoch 95/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0333\n",
      "Epoch 95: val_loss improved from 0.12464 to 0.12456, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0331 - val_loss: 0.1246\n",
      "Epoch 96/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0375\n",
      "Epoch 96: val_loss improved from 0.12456 to 0.12447, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0330 - val_loss: 0.1245\n",
      "Epoch 97/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0391\n",
      "Epoch 97: val_loss improved from 0.12447 to 0.12437, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0328 - val_loss: 0.1244\n",
      "Epoch 98/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0311\n",
      "Epoch 98: val_loss improved from 0.12437 to 0.12418, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0327 - val_loss: 0.1242\n",
      "Epoch 99/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0342\n",
      "Epoch 99: val_loss improved from 0.12418 to 0.12410, saving model to problem2_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0325 - val_loss: 0.1241\n",
      "Epoch 100/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0359\n",
      "Epoch 100: val_loss improved from 0.12410 to 0.12403, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0324 - val_loss: 0.1240\n",
      "Epoch 101/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0321\n",
      "Epoch 101: val_loss improved from 0.12403 to 0.12387, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0322 - val_loss: 0.1239\n",
      "Epoch 102/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0291\n",
      "Epoch 102: val_loss improved from 0.12387 to 0.12374, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0321 - val_loss: 0.1237\n",
      "Epoch 103/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0332\n",
      "Epoch 103: val_loss improved from 0.12374 to 0.12345, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0320 - val_loss: 0.1234\n",
      "Epoch 104/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0369\n",
      "Epoch 104: val_loss improved from 0.12345 to 0.12345, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0318 - val_loss: 0.1234\n",
      "Epoch 105/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0331\n",
      "Epoch 105: val_loss improved from 0.12345 to 0.12332, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0316 - val_loss: 0.1233\n",
      "Epoch 106/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0320\n",
      "Epoch 106: val_loss did not improve from 0.12332\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0315 - val_loss: 0.1234\n",
      "Epoch 107/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0358\n",
      "Epoch 107: val_loss did not improve from 0.12332\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0313 - val_loss: 0.1235\n",
      "Epoch 108/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0277\n",
      "Epoch 108: val_loss did not improve from 0.12332\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0312 - val_loss: 0.1234\n",
      "Epoch 109/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0344\n",
      "Epoch 109: val_loss did not improve from 0.12332\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0311 - val_loss: 0.1234\n",
      "Epoch 110/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0282\n",
      "Epoch 110: val_loss improved from 0.12332 to 0.12323, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0309 - val_loss: 0.1232\n",
      "Epoch 111/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0245\n",
      "Epoch 111: val_loss improved from 0.12323 to 0.12315, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0307 - val_loss: 0.1231\n",
      "Epoch 112/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0245\n",
      "Epoch 112: val_loss improved from 0.12315 to 0.12305, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0306 - val_loss: 0.1230\n",
      "Epoch 113/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0327\n",
      "Epoch 113: val_loss improved from 0.12305 to 0.12288, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0304 - val_loss: 0.1229\n",
      "Epoch 114/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0301\n",
      "Epoch 114: val_loss improved from 0.12288 to 0.12275, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0303 - val_loss: 0.1227\n",
      "Epoch 115/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0318\n",
      "Epoch 115: val_loss improved from 0.12275 to 0.12256, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0301 - val_loss: 0.1226\n",
      "Epoch 116/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0316\n",
      "Epoch 116: val_loss improved from 0.12256 to 0.12240, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0300 - val_loss: 0.1224\n",
      "Epoch 117/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0272\n",
      "Epoch 117: val_loss improved from 0.12240 to 0.12236, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0298 - val_loss: 0.1224\n",
      "Epoch 118/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0276\n",
      "Epoch 118: val_loss did not improve from 0.12236\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0296 - val_loss: 0.1224\n",
      "Epoch 119/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0254\n",
      "Epoch 119: val_loss did not improve from 0.12236\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0295 - val_loss: 0.1224\n",
      "Epoch 120/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0325\n",
      "Epoch 120: val_loss improved from 0.12236 to 0.12223, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0293 - val_loss: 0.1222\n",
      "Epoch 121/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0329\n",
      "Epoch 121: val_loss did not improve from 0.12223\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0292 - val_loss: 0.1222\n",
      "Epoch 122/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0331\n",
      "Epoch 122: val_loss improved from 0.12223 to 0.12208, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0290 - val_loss: 0.1221\n",
      "Epoch 123/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0281\n",
      "Epoch 123: val_loss improved from 0.12208 to 0.12204, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0289 - val_loss: 0.1220\n",
      "Epoch 124/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0254\n",
      "Epoch 124: val_loss improved from 0.12204 to 0.12192, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0287 - val_loss: 0.1219\n",
      "Epoch 125/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0248\n",
      "Epoch 125: val_loss improved from 0.12192 to 0.12175, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0286 - val_loss: 0.1218\n",
      "Epoch 126/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0265\n",
      "Epoch 126: val_loss improved from 0.12175 to 0.12160, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0284 - val_loss: 0.1216\n",
      "Epoch 127/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0288\n",
      "Epoch 127: val_loss improved from 0.12160 to 0.12135, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0283 - val_loss: 0.1213\n",
      "Epoch 128/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0246\n",
      "Epoch 128: val_loss did not improve from 0.12135\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0281 - val_loss: 0.1214\n",
      "Epoch 129/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0351\n",
      "Epoch 129: val_loss did not improve from 0.12135\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0280 - val_loss: 0.1213\n",
      "Epoch 130/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0274\n",
      "Epoch 130: val_loss did not improve from 0.12135\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0278 - val_loss: 0.1215\n",
      "Epoch 131/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0245\n",
      "Epoch 131: val_loss did not improve from 0.12135\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0276 - val_loss: 0.1215\n",
      "Epoch 132/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0194\n",
      "Epoch 132: val_loss improved from 0.12135 to 0.12133, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0275 - val_loss: 0.1213\n",
      "Epoch 133/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0243\n",
      "Epoch 133: val_loss did not improve from 0.12133\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0273 - val_loss: 0.1214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0248\n",
      "Epoch 134: val_loss improved from 0.12133 to 0.12121, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0272 - val_loss: 0.1212\n",
      "Epoch 135/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0290\n",
      "Epoch 135: val_loss improved from 0.12121 to 0.12105, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0270 - val_loss: 0.1210\n",
      "Epoch 136/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0198\n",
      "Epoch 136: val_loss did not improve from 0.12105\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0269 - val_loss: 0.1211\n",
      "Epoch 137/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0283\n",
      "Epoch 137: val_loss improved from 0.12105 to 0.12080, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0267 - val_loss: 0.1208\n",
      "Epoch 138/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0242\n",
      "Epoch 138: val_loss improved from 0.12080 to 0.12063, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0266 - val_loss: 0.1206\n",
      "Epoch 139/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0310\n",
      "Epoch 139: val_loss improved from 0.12063 to 0.12038, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0264 - val_loss: 0.1204\n",
      "Epoch 140/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0251\n",
      "Epoch 140: val_loss improved from 0.12038 to 0.12028, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0262 - val_loss: 0.1203\n",
      "Epoch 141/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0295\n",
      "Epoch 141: val_loss did not improve from 0.12028\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0261 - val_loss: 0.1203\n",
      "Epoch 142/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0244\n",
      "Epoch 142: val_loss improved from 0.12028 to 0.12023, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0259 - val_loss: 0.1202\n",
      "Epoch 143/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0260\n",
      "Epoch 143: val_loss improved from 0.12023 to 0.12016, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0258 - val_loss: 0.1202\n",
      "Epoch 144/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0277\n",
      "Epoch 144: val_loss improved from 0.12016 to 0.12003, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0257 - val_loss: 0.1200\n",
      "Epoch 145/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0259\n",
      "Epoch 145: val_loss did not improve from 0.12003\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0255 - val_loss: 0.1202\n",
      "Epoch 146/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0256\n",
      "Epoch 146: val_loss did not improve from 0.12003\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0254 - val_loss: 0.1204\n",
      "Epoch 147/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0237\n",
      "Epoch 147: val_loss did not improve from 0.12003\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0252 - val_loss: 0.1203\n",
      "Epoch 148/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0263\n",
      "Epoch 148: val_loss did not improve from 0.12003\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0251 - val_loss: 0.1201\n",
      "Epoch 149/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0245\n",
      "Epoch 149: val_loss did not improve from 0.12003\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0249 - val_loss: 0.1201\n"
     ]
    }
   ],
   "source": [
    "path_checkpoint = \"problem2_checkpoint.h5\"\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    # 要同时保存网络结构。\n",
    "    save_weights_only=False,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[es_callback, modelckpt_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b615e",
   "metadata": {},
   "source": [
    "对模型训练过程的损失函数和验证损失函数进行可视化。\n",
    "- 基于matplotlib的可视化；\n",
    "- 基于plotly的可视化；\n",
    "\n",
    "挑一个好看的就行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e784dfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_loss(history, title):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "visualize_loss(history, \"Training and Validation Loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
