{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74d806f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pathlib import Path as P\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['KaiTi', 'SimHei', 'FangSong']  # 汉字字体,优先使用楷体，如果找不到楷体，则使用黑体\n",
    "plt.rcParams['font.size'] = 12  # 字体大小\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 正常显示负号\n",
    "from collections import defaultdict\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86f3d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "train_size=0.8\n",
    "seqlen=12\n",
    "bs=32\n",
    "epochs=200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f343cd",
   "metadata": {},
   "source": [
    "这些是模型的超参数。\n",
    "- learning_rate 是学习率，控制模型收敛的快慢，太大了模型容易发散，太小了模型收敛很慢；\n",
    "- train_size 训练集占整个数据集的比例，一般是28开；\n",
    "- seqlen：序列长度，在时序建模中，就是用前几个样本来预测当前样本；\n",
    "- bs：batch size，批量大小，随机梯度下降算法SGD中，每次用来估计梯度的训练样本数量；\n",
    "考虑到数据集本身只有100多个样本，批量不用太大；\n",
    "- epochs：训练的轮数，即迭代次数；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2d95214",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('问题2-训练数据-归一化.csv',index_col='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc1bfb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, train_size=train_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969f38d",
   "metadata": {},
   "source": [
    "将数据集分割为训练集和验证集，二者没有交集，训练集用来训练模型，验证集用来确保模型没有过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d681a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((98, 6), (25, 6))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_size=df_train.shape[1]\n",
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7324e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    df_train.values, df_train.values, sequence_length=seqlen, batch_size=bs)\n",
    "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    df_val.values, df_val.values, sequence_length=seqlen, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c78d2",
   "metadata": {},
   "source": [
    "利用keras的接口构造时序模型需要的时序数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f086a78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<BatchDataset element_spec=(TensorSpec(shape=(None, None, 6), dtype=tf.float64, name=None), TensorSpec(shape=(None, 6), dtype=tf.float64, name=None))>,\n",
       " <BatchDataset element_spec=(TensorSpec(shape=(None, None, 6), dtype=tf.float64, name=None), TensorSpec(shape=(None, 6), dtype=tf.float64, name=None))>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train, dataset_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc88903d",
   "metadata": {},
   "source": [
    "构建一个单层的LSTM模型。LSTM是一种专门用来建模时序数据的神经网络模型，即长短期记忆（Long Short Term Memory）。\n",
    "可以展开说说理论。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "043354e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 12, 6)]           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 4)                 176       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 30        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 206\n",
      "Trainable params: 206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=(seqlen, feature_size))\n",
    "lstm_out = keras.layers.LSTM(4)(inputs)\n",
    "lstm_out = keras.layers.Dropout(0.1)(lstm_out)\n",
    "outputs = keras.layers.Dense(feature_size)(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce5aa7",
   "metadata": {},
   "source": [
    "训练模型：\n",
    "1. 使用的损失函数：MSE，Mean Square Error，即均方误差；\n",
    "2. 早停止：当验证误差经过一段时间不再改进之后，停止训练模型，这是一种停止训练循环的策略；\n",
    "3. 检查点：当验证误差出现改进时，保存当前的模型参数；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f710554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/3 [=========>....................] - ETA: 3s - loss: 0.2914\n",
      "Epoch 1: val_loss improved from inf to 0.41713, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 2s 242ms/step - loss: 0.2844 - val_loss: 0.4171\n",
      "Epoch 2/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2691\n",
      "Epoch 2: val_loss improved from 0.41713 to 0.39975, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.2639 - val_loss: 0.3998\n",
      "Epoch 3/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2586\n",
      "Epoch 3: val_loss improved from 0.39975 to 0.38364, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.2517 - val_loss: 0.3836\n",
      "Epoch 4/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2451\n",
      "Epoch 4: val_loss improved from 0.38364 to 0.36877, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.2425 - val_loss: 0.3688\n",
      "Epoch 5/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2330\n",
      "Epoch 5: val_loss improved from 0.36877 to 0.35511, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.2299 - val_loss: 0.3551\n",
      "Epoch 6/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2286\n",
      "Epoch 6: val_loss improved from 0.35511 to 0.34247, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.2252 - val_loss: 0.3425\n",
      "Epoch 7/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2182\n",
      "Epoch 7: val_loss improved from 0.34247 to 0.33083, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.2137 - val_loss: 0.3308\n",
      "Epoch 8/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2103\n",
      "Epoch 8: val_loss improved from 0.33083 to 0.32011, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.2061 - val_loss: 0.3201\n",
      "Epoch 9/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2009\n",
      "Epoch 9: val_loss improved from 0.32011 to 0.31027, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.1976 - val_loss: 0.3103\n",
      "Epoch 10/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1964\n",
      "Epoch 10: val_loss improved from 0.31027 to 0.30122, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.1920 - val_loss: 0.3012\n",
      "Epoch 11/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1898\n",
      "Epoch 11: val_loss improved from 0.30122 to 0.29289, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.1850 - val_loss: 0.2929\n",
      "Epoch 12/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1855\n",
      "Epoch 12: val_loss improved from 0.29289 to 0.28516, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.1805 - val_loss: 0.2852\n",
      "Epoch 13/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1799\n",
      "Epoch 13: val_loss improved from 0.28516 to 0.27795, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.1766 - val_loss: 0.2780\n",
      "Epoch 14/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1756\n",
      "Epoch 14: val_loss improved from 0.27795 to 0.27122, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.1709 - val_loss: 0.2712\n",
      "Epoch 15/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1711\n",
      "Epoch 15: val_loss improved from 0.27122 to 0.26492, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.1661 - val_loss: 0.2649\n",
      "Epoch 16/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1667\n",
      "Epoch 16: val_loss improved from 0.26492 to 0.25901, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1619 - val_loss: 0.2590\n",
      "Epoch 17/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1613\n",
      "Epoch 17: val_loss improved from 0.25901 to 0.25341, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.1573 - val_loss: 0.2534\n",
      "Epoch 18/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1571\n",
      "Epoch 18: val_loss improved from 0.25341 to 0.24811, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.1534 - val_loss: 0.2481\n",
      "Epoch 19/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1556\n",
      "Epoch 19: val_loss improved from 0.24811 to 0.24306, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.1503 - val_loss: 0.2431\n",
      "Epoch 20/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1564\n",
      "Epoch 20: val_loss improved from 0.24306 to 0.23826, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.1489 - val_loss: 0.2383\n",
      "Epoch 21/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1508\n",
      "Epoch 21: val_loss improved from 0.23826 to 0.23364, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1447 - val_loss: 0.2336\n",
      "Epoch 22/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1467\n",
      "Epoch 22: val_loss improved from 0.23364 to 0.22920, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1413 - val_loss: 0.2292\n",
      "Epoch 23/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1433\n",
      "Epoch 23: val_loss improved from 0.22920 to 0.22492, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1379 - val_loss: 0.2249\n",
      "Epoch 24/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1379\n",
      "Epoch 24: val_loss improved from 0.22492 to 0.22078, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1346 - val_loss: 0.2208\n",
      "Epoch 25/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1390\n",
      "Epoch 25: val_loss improved from 0.22078 to 0.21678, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.1331 - val_loss: 0.2168\n",
      "Epoch 26/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1341\n",
      "Epoch 26: val_loss improved from 0.21678 to 0.21289, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.1300 - val_loss: 0.2129\n",
      "Epoch 27/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1314\n",
      "Epoch 27: val_loss improved from 0.21289 to 0.20909, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1279 - val_loss: 0.2091\n",
      "Epoch 28/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1304\n",
      "Epoch 28: val_loss improved from 0.20909 to 0.20538, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.1245 - val_loss: 0.2054\n",
      "Epoch 29/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1291\n",
      "Epoch 29: val_loss improved from 0.20538 to 0.20177, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.1222 - val_loss: 0.2018\n",
      "Epoch 30/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1265\n",
      "Epoch 30: val_loss improved from 0.20177 to 0.19822, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.1211 - val_loss: 0.1982\n",
      "Epoch 31/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1258\n",
      "Epoch 31: val_loss improved from 0.19822 to 0.19473, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.1180 - val_loss: 0.1947\n",
      "Epoch 32/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1205\n",
      "Epoch 32: val_loss improved from 0.19473 to 0.19127, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.1154 - val_loss: 0.1913\n",
      "Epoch 33/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1207\n",
      "Epoch 33: val_loss improved from 0.19127 to 0.18787, saving model to problem2_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1135 - val_loss: 0.1879\n",
      "Epoch 34/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1171\n",
      "Epoch 34: val_loss improved from 0.18787 to 0.18450, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.1119 - val_loss: 0.1845\n",
      "Epoch 35/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1143\n",
      "Epoch 35: val_loss improved from 0.18450 to 0.18116, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.1082 - val_loss: 0.1812\n",
      "Epoch 36/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1100\n",
      "Epoch 36: val_loss improved from 0.18116 to 0.17785, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.1057 - val_loss: 0.1778\n",
      "Epoch 37/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1135\n",
      "Epoch 37: val_loss improved from 0.17785 to 0.17459, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.1064 - val_loss: 0.1746\n",
      "Epoch 38/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1066\n",
      "Epoch 38: val_loss improved from 0.17459 to 0.17137, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.1025 - val_loss: 0.1714\n",
      "Epoch 39/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1071\n",
      "Epoch 39: val_loss improved from 0.17137 to 0.16819, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1022 - val_loss: 0.1682\n",
      "Epoch 40/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1050\n",
      "Epoch 40: val_loss improved from 0.16819 to 0.16503, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0981 - val_loss: 0.1650\n",
      "Epoch 41/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1016\n",
      "Epoch 41: val_loss improved from 0.16503 to 0.16189, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0979 - val_loss: 0.1619\n",
      "Epoch 42/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1005\n",
      "Epoch 42: val_loss improved from 0.16189 to 0.15877, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0949 - val_loss: 0.1588\n",
      "Epoch 43/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0988\n",
      "Epoch 43: val_loss improved from 0.15877 to 0.15567, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0938 - val_loss: 0.1557\n",
      "Epoch 44/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0977\n",
      "Epoch 44: val_loss improved from 0.15567 to 0.15261, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0913 - val_loss: 0.1526\n",
      "Epoch 45/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0942\n",
      "Epoch 45: val_loss improved from 0.15261 to 0.14957, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0898 - val_loss: 0.1496\n",
      "Epoch 46/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0914\n",
      "Epoch 46: val_loss improved from 0.14957 to 0.14655, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0868 - val_loss: 0.1466\n",
      "Epoch 47/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0944\n",
      "Epoch 47: val_loss improved from 0.14655 to 0.14360, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0885 - val_loss: 0.1436\n",
      "Epoch 48/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0912\n",
      "Epoch 48: val_loss improved from 0.14360 to 0.14072, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0860 - val_loss: 0.1407\n",
      "Epoch 49/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0874\n",
      "Epoch 49: val_loss improved from 0.14072 to 0.13785, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0814 - val_loss: 0.1379\n",
      "Epoch 50/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0862\n",
      "Epoch 50: val_loss improved from 0.13785 to 0.13500, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0817 - val_loss: 0.1350\n",
      "Epoch 51/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0876\n",
      "Epoch 51: val_loss improved from 0.13500 to 0.13218, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0805 - val_loss: 0.1322\n",
      "Epoch 52/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0821\n",
      "Epoch 52: val_loss improved from 0.13218 to 0.12941, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0777 - val_loss: 0.1294\n",
      "Epoch 53/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0793\n",
      "Epoch 53: val_loss improved from 0.12941 to 0.12671, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0760 - val_loss: 0.1267\n",
      "Epoch 54/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0808\n",
      "Epoch 54: val_loss improved from 0.12671 to 0.12409, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0762 - val_loss: 0.1241\n",
      "Epoch 55/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0872\n",
      "Epoch 55: val_loss improved from 0.12409 to 0.12160, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0758 - val_loss: 0.1216\n",
      "Epoch 56/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0827\n",
      "Epoch 56: val_loss improved from 0.12160 to 0.11921, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0760 - val_loss: 0.1192\n",
      "Epoch 57/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0799\n",
      "Epoch 57: val_loss improved from 0.11921 to 0.11694, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0731 - val_loss: 0.1169\n",
      "Epoch 58/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0733\n",
      "Epoch 58: val_loss improved from 0.11694 to 0.11474, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0709 - val_loss: 0.1147\n",
      "Epoch 59/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0804\n",
      "Epoch 59: val_loss improved from 0.11474 to 0.11268, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0711 - val_loss: 0.1127\n",
      "Epoch 60/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0745\n",
      "Epoch 60: val_loss improved from 0.11268 to 0.11071, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0688 - val_loss: 0.1107\n",
      "Epoch 61/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0708\n",
      "Epoch 61: val_loss improved from 0.11071 to 0.10882, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0670 - val_loss: 0.1088\n",
      "Epoch 62/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0713\n",
      "Epoch 62: val_loss improved from 0.10882 to 0.10704, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0666 - val_loss: 0.1070\n",
      "Epoch 63/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0770\n",
      "Epoch 63: val_loss improved from 0.10704 to 0.10541, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0686 - val_loss: 0.1054\n",
      "Epoch 64/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0697\n",
      "Epoch 64: val_loss improved from 0.10541 to 0.10387, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0664 - val_loss: 0.1039\n",
      "Epoch 65/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0704\n",
      "Epoch 65: val_loss improved from 0.10387 to 0.10245, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0653 - val_loss: 0.1024\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0767\n",
      "Epoch 66: val_loss improved from 0.10245 to 0.10119, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0686 - val_loss: 0.1012\n",
      "Epoch 67/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0711\n",
      "Epoch 67: val_loss improved from 0.10119 to 0.10005, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0629 - val_loss: 0.1000\n",
      "Epoch 68/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0654\n",
      "Epoch 68: val_loss improved from 0.10005 to 0.09896, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0599 - val_loss: 0.0990\n",
      "Epoch 69/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0684\n",
      "Epoch 69: val_loss improved from 0.09896 to 0.09796, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0636 - val_loss: 0.0980\n",
      "Epoch 70/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0704\n",
      "Epoch 70: val_loss improved from 0.09796 to 0.09711, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0622 - val_loss: 0.0971\n",
      "Epoch 71/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0689\n",
      "Epoch 71: val_loss improved from 0.09711 to 0.09635, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0631 - val_loss: 0.0964\n",
      "Epoch 72/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0728\n",
      "Epoch 72: val_loss improved from 0.09635 to 0.09573, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0639 - val_loss: 0.0957\n",
      "Epoch 73/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0754\n",
      "Epoch 73: val_loss improved from 0.09573 to 0.09520, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0646 - val_loss: 0.0952\n",
      "Epoch 74/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0667\n",
      "Epoch 74: val_loss improved from 0.09520 to 0.09474, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0616 - val_loss: 0.0947\n",
      "Epoch 75/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0687\n",
      "Epoch 75: val_loss improved from 0.09474 to 0.09432, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0614 - val_loss: 0.0943\n",
      "Epoch 76/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0696\n",
      "Epoch 76: val_loss improved from 0.09432 to 0.09394, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0606 - val_loss: 0.0939\n",
      "Epoch 77/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0639\n",
      "Epoch 77: val_loss improved from 0.09394 to 0.09354, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0605 - val_loss: 0.0935\n",
      "Epoch 78/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0655\n",
      "Epoch 78: val_loss improved from 0.09354 to 0.09315, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0601 - val_loss: 0.0932\n",
      "Epoch 79/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0646\n",
      "Epoch 79: val_loss improved from 0.09315 to 0.09276, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0587 - val_loss: 0.0928\n",
      "Epoch 80/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0677\n",
      "Epoch 80: val_loss improved from 0.09276 to 0.09236, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0595 - val_loss: 0.0924\n",
      "Epoch 81/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0658\n",
      "Epoch 81: val_loss improved from 0.09236 to 0.09204, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0616 - val_loss: 0.0920\n",
      "Epoch 82/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0696\n",
      "Epoch 82: val_loss improved from 0.09204 to 0.09177, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0601 - val_loss: 0.0918\n",
      "Epoch 83/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0675\n",
      "Epoch 83: val_loss improved from 0.09177 to 0.09155, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0637 - val_loss: 0.0916\n",
      "Epoch 84/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0675\n",
      "Epoch 84: val_loss improved from 0.09155 to 0.09139, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0601 - val_loss: 0.0914\n",
      "Epoch 85/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0682\n",
      "Epoch 85: val_loss improved from 0.09139 to 0.09124, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0597 - val_loss: 0.0912\n",
      "Epoch 86/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0683\n",
      "Epoch 86: val_loss improved from 0.09124 to 0.09110, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0612 - val_loss: 0.0911\n",
      "Epoch 87/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0672\n",
      "Epoch 87: val_loss improved from 0.09110 to 0.09094, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0602 - val_loss: 0.0909\n",
      "Epoch 88/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0663\n",
      "Epoch 88: val_loss improved from 0.09094 to 0.09080, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0614 - val_loss: 0.0908\n",
      "Epoch 89/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0707\n",
      "Epoch 89: val_loss improved from 0.09080 to 0.09069, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0613 - val_loss: 0.0907\n",
      "Epoch 90/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0670\n",
      "Epoch 90: val_loss improved from 0.09069 to 0.09061, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0606 - val_loss: 0.0906\n",
      "Epoch 91/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0676\n",
      "Epoch 91: val_loss improved from 0.09061 to 0.09055, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0603 - val_loss: 0.0906\n",
      "Epoch 92/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0743\n",
      "Epoch 92: val_loss improved from 0.09055 to 0.09054, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0608 - val_loss: 0.0905\n",
      "Epoch 93/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0643\n",
      "Epoch 93: val_loss improved from 0.09054 to 0.09053, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0573 - val_loss: 0.0905\n",
      "Epoch 94/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0693\n",
      "Epoch 94: val_loss improved from 0.09053 to 0.09050, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0587 - val_loss: 0.0905\n",
      "Epoch 95/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0652\n",
      "Epoch 95: val_loss improved from 0.09050 to 0.09039, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0582 - val_loss: 0.0904\n",
      "Epoch 96/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0666\n",
      "Epoch 96: val_loss improved from 0.09039 to 0.09022, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0593 - val_loss: 0.0902\n",
      "Epoch 97/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0626\n",
      "Epoch 97: val_loss improved from 0.09022 to 0.09005, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0564 - val_loss: 0.0901\n",
      "Epoch 98/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0633\n",
      "Epoch 98: val_loss improved from 0.09005 to 0.08990, saving model to problem2_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0592 - val_loss: 0.0899\n",
      "Epoch 99/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0695\n",
      "Epoch 99: val_loss improved from 0.08990 to 0.08981, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0606 - val_loss: 0.0898\n",
      "Epoch 100/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0648\n",
      "Epoch 100: val_loss improved from 0.08981 to 0.08973, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0581 - val_loss: 0.0897\n",
      "Epoch 101/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0680\n",
      "Epoch 101: val_loss improved from 0.08973 to 0.08970, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0613 - val_loss: 0.0897\n",
      "Epoch 102/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0618\n",
      "Epoch 102: val_loss improved from 0.08970 to 0.08963, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0588 - val_loss: 0.0896\n",
      "Epoch 103/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0627\n",
      "Epoch 103: val_loss improved from 0.08963 to 0.08958, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0579 - val_loss: 0.0896\n",
      "Epoch 104/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0666\n",
      "Epoch 104: val_loss improved from 0.08958 to 0.08952, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0578 - val_loss: 0.0895\n",
      "Epoch 105/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0702\n",
      "Epoch 105: val_loss improved from 0.08952 to 0.08947, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0598 - val_loss: 0.0895\n",
      "Epoch 106/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0642\n",
      "Epoch 106: val_loss improved from 0.08947 to 0.08943, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0618 - val_loss: 0.0894\n",
      "Epoch 107/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0637\n",
      "Epoch 107: val_loss improved from 0.08943 to 0.08940, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0574 - val_loss: 0.0894\n",
      "Epoch 108/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0685\n",
      "Epoch 108: val_loss improved from 0.08940 to 0.08938, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0602 - val_loss: 0.0894\n",
      "Epoch 109/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0705\n",
      "Epoch 109: val_loss improved from 0.08938 to 0.08935, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0588 - val_loss: 0.0894\n",
      "Epoch 110/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0732\n",
      "Epoch 110: val_loss improved from 0.08935 to 0.08926, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0619 - val_loss: 0.0893\n",
      "Epoch 111/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0611\n",
      "Epoch 111: val_loss improved from 0.08926 to 0.08916, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0578 - val_loss: 0.0892\n",
      "Epoch 112/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0642\n",
      "Epoch 112: val_loss improved from 0.08916 to 0.08909, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0579 - val_loss: 0.0891\n",
      "Epoch 113/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0638\n",
      "Epoch 113: val_loss improved from 0.08909 to 0.08903, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0576 - val_loss: 0.0890\n",
      "Epoch 114/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0649\n",
      "Epoch 114: val_loss improved from 0.08903 to 0.08898, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0576 - val_loss: 0.0890\n",
      "Epoch 115/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0682\n",
      "Epoch 115: val_loss improved from 0.08898 to 0.08897, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0612 - val_loss: 0.0890\n",
      "Epoch 116/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0643\n",
      "Epoch 116: val_loss did not improve from 0.08897\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0594 - val_loss: 0.0890\n",
      "Epoch 117/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0667\n",
      "Epoch 117: val_loss did not improve from 0.08897\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0597 - val_loss: 0.0891\n",
      "Epoch 118/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0655\n",
      "Epoch 118: val_loss did not improve from 0.08897\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0603 - val_loss: 0.0891\n",
      "Epoch 119/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0664\n",
      "Epoch 119: val_loss did not improve from 0.08897\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0581 - val_loss: 0.0890\n",
      "Epoch 120/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0632\n",
      "Epoch 120: val_loss improved from 0.08897 to 0.08891, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0576 - val_loss: 0.0889\n",
      "Epoch 121/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0647\n",
      "Epoch 121: val_loss improved from 0.08891 to 0.08883, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0598 - val_loss: 0.0888\n",
      "Epoch 122/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0679\n",
      "Epoch 122: val_loss improved from 0.08883 to 0.08875, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0598 - val_loss: 0.0887\n",
      "Epoch 123/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0733\n",
      "Epoch 123: val_loss improved from 0.08875 to 0.08870, saving model to problem2_checkpoint.h5\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0617 - val_loss: 0.0887\n",
      "Epoch 124/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0648\n",
      "Epoch 124: val_loss did not improve from 0.08870\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0557 - val_loss: 0.0887\n",
      "Epoch 125/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0686\n",
      "Epoch 125: val_loss did not improve from 0.08870\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0571 - val_loss: 0.0887\n",
      "Epoch 126/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0634\n",
      "Epoch 126: val_loss did not improve from 0.08870\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0589 - val_loss: 0.0887\n",
      "Epoch 127/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0659\n",
      "Epoch 127: val_loss did not improve from 0.08870\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0573 - val_loss: 0.0888\n",
      "Epoch 128/200\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0672\n",
      "Epoch 128: val_loss did not improve from 0.08870\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0580 - val_loss: 0.0889\n"
     ]
    }
   ],
   "source": [
    "path_checkpoint = \"problem2_checkpoint.h5\"\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    # 要同时保存网络结构。\n",
    "    save_weights_only=False,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[es_callback, modelckpt_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aec7c5",
   "metadata": {},
   "source": [
    "对模型训练过程的损失函数和验证损失函数进行可视化。\n",
    "- 基于matplotlib的可视化；\n",
    "- 基于plotly的可视化；\n",
    "\n",
    "挑一个好看的就行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66ca2145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_loss(history, title):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "visualize_loss(history, \"Training and Validation Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b42e7b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=Training loss<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "Training loss",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Training loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127
         ],
         "xaxis": "x",
         "y": [
          0.28439682722091675,
          0.2639225125312805,
          0.25172775983810425,
          0.24248768389225006,
          0.22987788915634155,
          0.22521626949310303,
          0.21367837488651276,
          0.20605133473873138,
          0.1975649893283844,
          0.1919746845960617,
          0.18501926958560944,
          0.18047945201396942,
          0.17655910551548004,
          0.17092086374759674,
          0.1661359965801239,
          0.16190609335899353,
          0.15726497769355774,
          0.15344639122486115,
          0.15032538771629333,
          0.1489202082157135,
          0.1446772813796997,
          0.14129826426506042,
          0.13792535662651062,
          0.13464154303073883,
          0.13306839764118195,
          0.13001196086406708,
          0.12791188061237335,
          0.12448852509260178,
          0.12221699953079224,
          0.12112493813037872,
          0.11800598353147507,
          0.11537998169660568,
          0.11346694082021713,
          0.11186511069536209,
          0.10820791125297546,
          0.10568272322416306,
          0.10641223192214966,
          0.10250026732683182,
          0.10217878222465515,
          0.09810938686132431,
          0.09788841754198074,
          0.09492433816194534,
          0.09376592934131622,
          0.09134121239185333,
          0.0897882878780365,
          0.08679763972759247,
          0.08852982521057129,
          0.08598142117261887,
          0.08139414340257645,
          0.08166822046041489,
          0.08050917834043503,
          0.07766517251729965,
          0.07598842680454254,
          0.07623223215341568,
          0.07578422874212265,
          0.07597198337316513,
          0.07314179837703705,
          0.07093437761068344,
          0.07109328359365463,
          0.06880129128694534,
          0.06697636842727661,
          0.06663575023412704,
          0.0686340257525444,
          0.06641127914190292,
          0.06534644216299057,
          0.06857970356941223,
          0.06289516389369965,
          0.059852320700883865,
          0.06363969296216965,
          0.06219887360930443,
          0.06313980370759964,
          0.06393265724182129,
          0.06461814045906067,
          0.0616406574845314,
          0.061371929943561554,
          0.060616087168455124,
          0.060469742864370346,
          0.0600765161216259,
          0.05867564678192139,
          0.059451594948768616,
          0.0615718774497509,
          0.06011847406625748,
          0.06371331214904785,
          0.06013499200344086,
          0.05973276123404503,
          0.06118284910917282,
          0.06019901856780052,
          0.061369139701128006,
          0.061334915459156036,
          0.06059587001800537,
          0.060283102095127106,
          0.060780905187129974,
          0.05726252868771553,
          0.058730918914079666,
          0.05823468789458275,
          0.059257298707962036,
          0.05643218755722046,
          0.05916707217693329,
          0.060576267540454865,
          0.05808625742793083,
          0.06132211536169052,
          0.05877913162112236,
          0.057894017547369,
          0.057794734835624695,
          0.059841059148311615,
          0.06184735894203186,
          0.05738003924489021,
          0.060204390436410904,
          0.058833781629800797,
          0.06193629652261734,
          0.05780769884586334,
          0.0579393208026886,
          0.05759916454553604,
          0.05763230472803116,
          0.06123992055654526,
          0.059379808604717255,
          0.05965513363480568,
          0.060347940772771835,
          0.05812912806868553,
          0.057579923421144485,
          0.05983676761388779,
          0.05984741076827049,
          0.06169496104121208,
          0.05569151043891907,
          0.05707620084285736,
          0.05885491892695427,
          0.057329293340444565,
          0.05796561762690544
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=Validation loss<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "Validation loss",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Validation loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127
         ],
         "xaxis": "x",
         "y": [
          0.4171283543109894,
          0.3997512757778168,
          0.3836371600627899,
          0.3687678277492523,
          0.3551051914691925,
          0.34247127175331116,
          0.3308268189430237,
          0.3201090395450592,
          0.3102748692035675,
          0.3012155592441559,
          0.2928907871246338,
          0.28515979647636414,
          0.2779545783996582,
          0.27122119069099426,
          0.2649177610874176,
          0.2590070068836212,
          0.2534102499485016,
          0.24810539186000824,
          0.24306340515613556,
          0.23825614154338837,
          0.2336437702178955,
          0.2292032688856125,
          0.2249191552400589,
          0.22077950835227966,
          0.2167784422636032,
          0.2128879278898239,
          0.20909300446510315,
          0.2053847312927246,
          0.2017659842967987,
          0.1982155740261078,
          0.19473052024841309,
          0.19127321243286133,
          0.1878667026758194,
          0.18449759483337402,
          0.18116387724876404,
          0.17784500122070312,
          0.17458927631378174,
          0.17137135565280914,
          0.16819466650485992,
          0.16502952575683594,
          0.1618863344192505,
          0.15876899659633636,
          0.1556748002767563,
          0.1526130884885788,
          0.14957214891910553,
          0.14655467867851257,
          0.14359986782073975,
          0.14071722328662872,
          0.13785341382026672,
          0.1349954903125763,
          0.13217803835868835,
          0.1294143795967102,
          0.1267062872648239,
          0.12409115582704544,
          0.12159644067287445,
          0.11921357363462448,
          0.11693556606769562,
          0.11474473774433136,
          0.11268226057291031,
          0.11071006208658218,
          0.10882245004177094,
          0.1070442721247673,
          0.10540854185819626,
          0.10386587679386139,
          0.10244929045438766,
          0.10119136422872543,
          0.10004900395870209,
          0.09896273910999298,
          0.09796462208032608,
          0.09710556268692017,
          0.09635043889284134,
          0.09572585672140121,
          0.09520300477743149,
          0.09474456310272217,
          0.09432276338338852,
          0.0939350575208664,
          0.09354417026042938,
          0.09315209090709686,
          0.09275525063276291,
          0.09236007183790207,
          0.09204090386629105,
          0.09176790714263916,
          0.09155305474996567,
          0.09138556569814682,
          0.0912356898188591,
          0.09110040962696075,
          0.09094279259443283,
          0.09080232679843903,
          0.09069488942623138,
          0.09061181545257568,
          0.09055043756961823,
          0.0905374214053154,
          0.09053343534469604,
          0.09049529582262039,
          0.09038513153791428,
          0.09021981805562973,
          0.09005169570446014,
          0.08990151435136795,
          0.0898115262389183,
          0.08972644060850143,
          0.08969883620738983,
          0.089631088078022,
          0.08957893401384354,
          0.08952032029628754,
          0.08947009593248367,
          0.0894317552447319,
          0.08939606696367264,
          0.08937998861074448,
          0.0893508791923523,
          0.08926450461149216,
          0.08915857970714569,
          0.08909254521131516,
          0.08903462439775467,
          0.08897515386343002,
          0.0889669731259346,
          0.08900483697652817,
          0.08906684815883636,
          0.08907680958509445,
          0.08903606981039047,
          0.08891119807958603,
          0.08882928639650345,
          0.0887494683265686,
          0.08869651705026627,
          0.08869801461696625,
          0.08869921416044235,
          0.08872752636671066,
          0.08880650997161865,
          0.08887676149606705
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": ""
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training and Validation Loss"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Loss"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"7ac8e384-76c0-4410-9c40-ba3380094148\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7ac8e384-76c0-4410-9c40-ba3380094148\")) {                    Plotly.newPlot(                        \"7ac8e384-76c0-4410-9c40-ba3380094148\",                        [{\"hovertemplate\":\"variable=Training loss<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"Training loss\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Training loss\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127],\"xaxis\":\"x\",\"y\":[0.28439682722091675,0.2639225125312805,0.25172775983810425,0.24248768389225006,0.22987788915634155,0.22521626949310303,0.21367837488651276,0.20605133473873138,0.1975649893283844,0.1919746845960617,0.18501926958560944,0.18047945201396942,0.17655910551548004,0.17092086374759674,0.1661359965801239,0.16190609335899353,0.15726497769355774,0.15344639122486115,0.15032538771629333,0.1489202082157135,0.1446772813796997,0.14129826426506042,0.13792535662651062,0.13464154303073883,0.13306839764118195,0.13001196086406708,0.12791188061237335,0.12448852509260178,0.12221699953079224,0.12112493813037872,0.11800598353147507,0.11537998169660568,0.11346694082021713,0.11186511069536209,0.10820791125297546,0.10568272322416306,0.10641223192214966,0.10250026732683182,0.10217878222465515,0.09810938686132431,0.09788841754198074,0.09492433816194534,0.09376592934131622,0.09134121239185333,0.0897882878780365,0.08679763972759247,0.08852982521057129,0.08598142117261887,0.08139414340257645,0.08166822046041489,0.08050917834043503,0.07766517251729965,0.07598842680454254,0.07623223215341568,0.07578422874212265,0.07597198337316513,0.07314179837703705,0.07093437761068344,0.07109328359365463,0.06880129128694534,0.06697636842727661,0.06663575023412704,0.0686340257525444,0.06641127914190292,0.06534644216299057,0.06857970356941223,0.06289516389369965,0.059852320700883865,0.06363969296216965,0.06219887360930443,0.06313980370759964,0.06393265724182129,0.06461814045906067,0.0616406574845314,0.061371929943561554,0.060616087168455124,0.060469742864370346,0.0600765161216259,0.05867564678192139,0.059451594948768616,0.0615718774497509,0.06011847406625748,0.06371331214904785,0.06013499200344086,0.05973276123404503,0.06118284910917282,0.06019901856780052,0.061369139701128006,0.061334915459156036,0.06059587001800537,0.060283102095127106,0.060780905187129974,0.05726252868771553,0.058730918914079666,0.05823468789458275,0.059257298707962036,0.05643218755722046,0.05916707217693329,0.060576267540454865,0.05808625742793083,0.06132211536169052,0.05877913162112236,0.057894017547369,0.057794734835624695,0.059841059148311615,0.06184735894203186,0.05738003924489021,0.060204390436410904,0.058833781629800797,0.06193629652261734,0.05780769884586334,0.0579393208026886,0.05759916454553604,0.05763230472803116,0.06123992055654526,0.059379808604717255,0.05965513363480568,0.060347940772771835,0.05812912806868553,0.057579923421144485,0.05983676761388779,0.05984741076827049,0.06169496104121208,0.05569151043891907,0.05707620084285736,0.05885491892695427,0.057329293340444565,0.05796561762690544],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"variable=Validation loss<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"Validation loss\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Validation loss\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127],\"xaxis\":\"x\",\"y\":[0.4171283543109894,0.3997512757778168,0.3836371600627899,0.3687678277492523,0.3551051914691925,0.34247127175331116,0.3308268189430237,0.3201090395450592,0.3102748692035675,0.3012155592441559,0.2928907871246338,0.28515979647636414,0.2779545783996582,0.27122119069099426,0.2649177610874176,0.2590070068836212,0.2534102499485016,0.24810539186000824,0.24306340515613556,0.23825614154338837,0.2336437702178955,0.2292032688856125,0.2249191552400589,0.22077950835227966,0.2167784422636032,0.2128879278898239,0.20909300446510315,0.2053847312927246,0.2017659842967987,0.1982155740261078,0.19473052024841309,0.19127321243286133,0.1878667026758194,0.18449759483337402,0.18116387724876404,0.17784500122070312,0.17458927631378174,0.17137135565280914,0.16819466650485992,0.16502952575683594,0.1618863344192505,0.15876899659633636,0.1556748002767563,0.1526130884885788,0.14957214891910553,0.14655467867851257,0.14359986782073975,0.14071722328662872,0.13785341382026672,0.1349954903125763,0.13217803835868835,0.1294143795967102,0.1267062872648239,0.12409115582704544,0.12159644067287445,0.11921357363462448,0.11693556606769562,0.11474473774433136,0.11268226057291031,0.11071006208658218,0.10882245004177094,0.1070442721247673,0.10540854185819626,0.10386587679386139,0.10244929045438766,0.10119136422872543,0.10004900395870209,0.09896273910999298,0.09796462208032608,0.09710556268692017,0.09635043889284134,0.09572585672140121,0.09520300477743149,0.09474456310272217,0.09432276338338852,0.0939350575208664,0.09354417026042938,0.09315209090709686,0.09275525063276291,0.09236007183790207,0.09204090386629105,0.09176790714263916,0.09155305474996567,0.09138556569814682,0.0912356898188591,0.09110040962696075,0.09094279259443283,0.09080232679843903,0.09069488942623138,0.09061181545257568,0.09055043756961823,0.0905374214053154,0.09053343534469604,0.09049529582262039,0.09038513153791428,0.09021981805562973,0.09005169570446014,0.08990151435136795,0.0898115262389183,0.08972644060850143,0.08969883620738983,0.089631088078022,0.08957893401384354,0.08952032029628754,0.08947009593248367,0.0894317552447319,0.08939606696367264,0.08937998861074448,0.0893508791923523,0.08926450461149216,0.08915857970714569,0.08909254521131516,0.08903462439775467,0.08897515386343002,0.0889669731259346,0.08900483697652817,0.08906684815883636,0.08907680958509445,0.08903606981039047,0.08891119807958603,0.08882928639650345,0.0887494683265686,0.08869651705026627,0.08869801461696625,0.08869921416044235,0.08872752636671066,0.08880650997161865,0.08887676149606705],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"}},\"legend\":{\"title\":{\"text\":\"\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Training and Validation Loss\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('7ac8e384-76c0-4410-9c40-ba3380094148');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_loss_px(history, title):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    df=pd.DataFrame(data={'Training loss': loss, 'Validation loss': val_loss})\n",
    "    return px.line(df, y=df.columns).update_layout(xaxis_title='Epochs', yaxis_title='Loss',legend_title='',title=title)\n",
    "\n",
    "visualize_loss_px(history, \"Training and Validation Loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
